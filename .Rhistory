# Adding to the lists in order to export the correct matrix
Train_sets_LOO = rbind (Train_sets_LOO, c('Null',rep(0,(ncol(dataset_full)-length(Train_set_LOO_accuracy)-1)),Train_set_LOO_accuracy))
Test_sets_LOO  = rbind (Test_sets_LOO,  c('Null',rep(0,(ncol(dataset_full)-length(Test_set_LOO_accuracy) -1)), Test_set_LOO_accuracy))
Test_sets_stratified_split  = rbind (Test_sets_stratified_split,  c('Null',rep(0,(ncol(dataset_full)-length(Test_set_stratified_accuracy) -1)), Test_set_stratified_accuracy))
Train_sets_stratified_split = rbind (Train_sets_stratified_split, c('Null',rep(0,(ncol(dataset_full)-length(Train_set_stratified_accuracy)-1)), Train_set_stratified_accuracy))
###################### Perform all Tasks with different combinations of metadata ############
for (Ncomb in 1: (ncol(meta_file)-3)){
# Create a vector of all possible feature combinations
effector_combinations = combinations(v = effectors,r = Ncomb, repeats.allowed = F, n = length(effectors))
# Loop to select all possible combinations of features from the dataset
for (combination in 1:nrow(effector_combinations)){
# Select the table with the corresponding features on the corresponding timepoint
files = meta_file[,c('Sample','Timepoint',effector_combinations[combination,])]
###################### Leave one out Combinations #######################################################
# Calculate mean accuracy of prediction on final timepoint, via Leave One Out method of splitting Train-Test sets
LOO_multilogreg_One <- function (dataset_full,timepoint,end_timepoint,meta_file,Ncomb, splitting_times){
logreg <- as.data.frame(matrix(NA,nrow = nrow(dataset_full),ncol = ncol(meta_file)))
colnames(logreg)= c(paste('Cluster_at',end_timepoint,sep = '_'), timepoint , colnames(meta_file)[3:ncol(meta_file)])
rownames(logreg)= rownames(dataset_full)
for (modeling_sample in (rownames(dataset_full))){
subTab = meta_file[meta_file[,1] %in% modeling_sample & meta_file[,2] == as.numeric(end_timepoint), 3:ncol(meta_file)]
if (Ncomb > 1 ){
if(nrow(subTab) == 1){
logreg[modeling_sample, colnames(meta_file)[3:ncol(meta_file)]] = subTab
}
}
else if (Ncomb == 1){
if (length(subTab) == 1){
logreg[modeling_sample, colnames(meta_file)[3:ncol(meta_file)]] = subTab
}
}
logreg[modeling_sample, 2] = ifelse(test = length(dataset_full[modeling_sample,timepoint]), yes = dataset_full[modeling_sample,timepoint], no = NA)
logreg[modeling_sample, 1] = ifelse(test = length(dataset_full[modeling_sample,as.character(end_timepoint)]), yes = dataset_full[modeling_sample,as.character(end_timepoint)], no = NA)
}
logreg = logreg[complete.cases(logreg),]
acc <- c()
tra <- c()
form = as.formula(paste(paste('Cluster_at',end_timepoint,sep = '_'),'~.',sep = ''))
for (repeat_time in 1:splitting_times){
for (j in 1:nrow(logreg)){
trainset = logreg[1:nrow(logreg)!=j,]
testset = logreg[j,]
prediction_model <- multinom(formula = form , data = trainset ,censored = T, model = T)
training_set_accuracies <- prediction_model %>% predict(trainset[,2:ncol(trainset)])
test_set_predictions <- prediction_model %>% predict(testset[,2:ncol(testset)])
acc[j] = (sum(test_set_predictions == testset[,1])/ nrow(testset)) *100
tra[j] = (sum(test_set_predictions == trainset[,1])/nrow(trainset))*100
}
}
return (c(mean(tra),mean(acc)))
}
###################### Stratified Train/Test splits Combinations ########################################
# Calculate accuracy of prediction on final timepoint, as a mean of 100 accuracies with different
# Train-Test stratified splits. Stratfication is performed on all metadata categories
multilogreg_stratified_One <- function(dataset_full,optimal_splitting_percentage,timepoint,end_timepoint,meta_file,Ncomb,splitting_times){
logreg <- as.data.frame(matrix(NA,nrow = nrow(dataset_full),ncol = ncol(meta_file)))
colnames(logreg)= c(paste('Cluster_at',end_timepoint,sep = '_'),timepoint,colnames(meta_file)[3:ncol(meta_file)])
rownames(logreg)= rownames(dataset_full)
for (modeling_sample in (rownames(dataset_full))){
subTab = meta_file[meta_file[,1] %in% modeling_sample & meta_file[,2] == as.numeric(end_timepoint), 3:ncol(meta_file)]
if (Ncomb > 1){
if (nrow(subTab) == 1){
logreg[modeling_sample, colnames(meta_file)[3:ncol(meta_file)]] = subTab
}
}
else if (Ncomb == 1){
if (length(subTab) == 1){
logreg[modeling_sample, colnames(meta_file)[3:ncol(meta_file)]] = subTab
}
}
logreg[modeling_sample, 2] = ifelse(test = length(dataset_full[modeling_sample,timepoint]), yes = dataset_full[modeling_sample,timepoint], no = NA)
logreg[modeling_sample, 1] = ifelse(test = length(dataset_full[modeling_sample,as.character(end_timepoint)]), yes = dataset_full[modeling_sample,as.character(end_timepoint)], no = NA)
}
logreg = logreg[complete.cases(logreg),]
train_index <- createDataPartition(y = logreg[,paste('Cluster_at',end_timepoint,sep = '_')], p = optimal_splitting_percentage, list = F, times = splitting_times, groups = max(apply(X = logreg, MARGIN = 2, FUN = function(x){length(unique(x))})) )
acc <- c()
tra <- c()
fo = as.formula(paste(paste('Cluster_at',end_timepoint,sep = '_'),'~.',sep = ''))
for (j in 1:ncol(train_index)){
trainset = logreg[train_index[,j],]
testset = logreg[-train_index[,j],]
if (all(apply(X = logreg, MARGIN = 2, FUN = function(x){length(unique(x))})== apply(X = trainset, MARGIN = 2, FUN = function(x){length(unique(x))}))){
prediction_model <- multinom(formula = fo, data = trainset ,censored = T, model = T)
training_set_accuracies <- prediction_model %>% predict(trainset[,2:ncol(trainset)])
test_set_predictions <- prediction_model %>% predict(testset[,2:ncol(testset)])
acc[j] = (sum(test_set_predictions == testset[,1])/ nrow(testset)) *100
tra[j] = (sum(training_set_accuracies == trainset[,1])/nrow(trainset))*100
}
}
acc = na.omit(acc)
tra = na.omit(tra)
Test_set_stratified_accuracy <- mean(acc)
Train_set_stratified_accuracy = mean(tra)
trainsd <- sd(tra)
testsd <- sd(acc)
return (c(Test_set_stratified_accuracy,Train_set_stratified_accuracy, trainsd,testsd))
}
###################### Calculate optimal split percentage ############################################
# Calculate the optimal split percentage between .65 and .90 for predicting the final timepoint on the
# exact previous one to be used in all splits for all timepoints. The criterion is the best accuracy
# as derived by the previous function with argument the different percentages.
optimal_splitting_percentage <- function (dataset_full){
all_calculated_accuracies <- c()
best_splitting_percentage <- c()
for (percentage_to_calculate in 65:90){
percentage_to_calculate = percentage_to_calculate/100
telika <- multilogreg_stratified_One(dataset_full = dataset_full, optimal_splitting_percentage = percentage_to_calculate, timepoint = tail(timepoints_to_perform,1), end_timepoint = end_timepoint,meta_file = files,Ncomb = Ncomb,splitting_times = splitting_times)
Test_set_stratified_accuracy = telika[1]
Train_set_stratified_accuracy = telika[2]
trainsd = telika[3]
testsd = telika[4]
all_calculated_accuracies= c(all_calculated_accuracies,Test_set_stratified_accuracy)
best_splitting_percentage = c(best_splitting_percentage,percentage_to_calculate)
}
return (best_splitting_percentage[which.max(all_calculated_accuracies)])
}
# Assign the best percentage on a variable to use on the final calculations
optimal_splitting_percentage <- optimal_splitting_percentage(dataset_full = dataset_full)
###################### Initializing variables Combinations ########################################
Test_set_LOO_accuracy <- c()
Train_set_LOO_accuracy <-c()
Test_set_stratified_accuracy <- c()
Train_set_stratified_accuracy <- c()
trainsd <- c()
testsd <- c()
###################### Calculate Accuracies on timepoints Combinations ############################
# Loop to create a model from every timepoint to the final timepoint as selected from the first loop
for (timepoint in timepoints_to_perform){
LOOTeliko <- LOO_multilogreg_One(dataset_full = dataset_full, timepoint = timepoint,end_timepoint = end_timepoint,meta_file = files,Ncomb = Ncomb, splitting_times = splitting_times)
Train_set_LOO_accuracy = c(Train_set_LOO_accuracy,LOOTeliko[1])
Test_set_LOO_accuracy = c(Test_set_LOO_accuracy,LOOTeliko[2])
MultiLogReg_results <- multilogreg_stratified_One(dataset_full = dataset_full, optimal_splitting_percentage = optimal_splitting_percentage,timepoint =  timepoint,meta_file =  files, end_timepoint = end_timepoint, Ncomb = Ncomb,splitting_times = splitting_times)
Test_set_stratified_accuracy <- c(Test_set_stratified_accuracy,MultiLogReg_results[1])
Train_set_stratified_accuracy <- c(Train_set_stratified_accuracy, MultiLogReg_results[2])
trainsd <- c(trainsd, MultiLogReg_results[3])
testsd <- c(testsd, MultiLogReg_results[4])
}
###################### Save accuracies on the lists ######################################
# Select the effects that created the model
effect = paste(effector_combinations[combination,],collapse = ' & ')
# Adding to the lists in order to export the correct matrix
Train_sets_LOO = rbind (Train_sets_LOO, c(effect,rep(0,(ncol(dataset_full)-length(Train_set_LOO_accuracy)-1)),   Train_set_LOO_accuracy))
Test_sets_LOO  = rbind (Test_sets_LOO,  c(effect,rep(0,(ncol(dataset_full)-length(Test_set_LOO_accuracy)-1)),    Test_set_LOO_accuracy))
Test_sets_stratified_split  = rbind (Test_sets_stratified_split,  c(effect,rep(0,(ncol(dataset_full)-length(Test_set_stratified_accuracy)-1)), Test_set_stratified_accuracy))
Train_sets_stratified_split = rbind (Train_sets_stratified_split, c(effect,rep(0,(ncol(dataset_full)-length(Train_set_stratified_accuracy)-1)),Train_set_stratified_accuracy))
}
}
###################### Leave one out All #######################################
# Calculate mean accuracy of prediction on final timepoint, via Leave One Out method of splitting Train-Test sets
LOO_multilogreg <- function (dataset_full,timepoint, end_timepoint, splitting_times){
# Create the matrix with columns the state on the timepoint, the metadata and as a response the state on the last timepoint
logreg <- as.data.frame(matrix(NA,nrow = nrow(dataset_full),ncol = ncol(meta_file)))
colnames(logreg)= c(paste('Cluster_at',end_timepoint,sep = '_'), timepoint , colnames(meta_file)[3:ncol(meta_file)])
rownames(logreg)= rownames(dataset_full)
for (modeling_sample in (rownames(dataset_full))){
subTab = meta_file[meta_file[,1] %in% modeling_sample & meta_file[,2] == as.numeric(end_timepoint), 3:ncol(meta_file)]
if (nrow(subTab) == 1){
logreg[modeling_sample, colnames(meta_file)[3:ncol(meta_file)]] = subTab[1,]
}
logreg[modeling_sample, 2] = ifelse(test = length(dataset_full[modeling_sample,timepoint]), yes = dataset_full[modeling_sample,timepoint], no = NA)
logreg[modeling_sample, 1] = ifelse(test = length(dataset_full[modeling_sample,as.character(end_timepoint)]), yes = dataset_full[modeling_sample,as.character(end_timepoint)], no = NA)
}
# Remove NAs
logreg = logreg[complete.cases(logreg),]
# Set the response variable
fo = as.formula(paste(paste('Cluster_at',end_timepoint,sep = '_'),'~.',sep = ''))
acc <- c()
tra <- c()
for (repeat_time in 1:splitting_times){
for (j in 1:nrow(logreg)){
# Setting training and test sets by leaving one out
trainset = logreg[1:nrow(logreg)!=j,]
testset = logreg[j,]
# Train the model
prediction_model <- multinom(formula = fo , data = trainset ,censored = T, model = T)
# Predict for trainset
training_set_accuracies <- prediction_model %>% predict(trainset)
# Predict for testset
test_set_predictions <- prediction_model %>% predict(testset)
# Calculate accuracies
acc[j] = (sum(test_set_predictions == testset[,1])/ nrow(testset)) *100
tra[j] = (sum(test_set_predictions == trainset[,1])/nrow(trainset))*100
}
}
return (c(mean(tra),mean(acc)))
}
###################### Stratified Train/Test splits All ########################
# Calculate accuracy of prediction on final timepoint, as a mean of 100 accuracies with different
# Train-Test stratified splits. Stratfication is performed on all metadata categories
multilogreg_stratified <- function(dataset_full,optimal_splitting_percentage,timepoint,times, end_timepoint,splitting_times){
# Create the matrix with columns the state on the timepoint, the metadata and as a response the state on the last timepoint
logreg <- as.data.frame(matrix(NA,nrow = nrow(dataset_full),ncol = ncol(meta_file)))
colnames(logreg)= c(paste('Cluster_at',end_timepoint,sep = '_'),timepoint,colnames(meta_file)[3:ncol(meta_file)])
rownames(logreg)= rownames(dataset_full)
for (modeling_sample in (rownames(dataset_full))){
subTab = meta_file[meta_file[,1] %in% modeling_sample & meta_file[,2] == as.numeric(end_timepoint), 3:ncol(meta_file)]
if (nrow(subTab) == 1){
logreg[modeling_sample, colnames(meta_file)[3:ncol(meta_file)]] = subTab[1,]
}
logreg[modeling_sample, 2] = ifelse(test = length(dataset_full[modeling_sample,timepoint]), yes = dataset_full[modeling_sample,timepoint], no = NA)
logreg[modeling_sample, 1] = ifelse(test = length(dataset_full[modeling_sample,as.character(end_timepoint)]), yes = dataset_full[modeling_sample,as.character(end_timepoint)], no = NA)
}
# Remove NAs
logreg = logreg[complete.cases(logreg),]
# Create different partitions to split train and test sets
train_index <- createDataPartition(y = logreg[,paste('Cluster_at',end_timepoint,sep = '_')], p = optimal_splitting_percentage, list = F, times = splitting_times, groups = max(apply(X = logreg, MARGIN = 2, FUN = function(x){length(unique(x))})) )
# Set the response variable
fo = as.formula(paste(paste('Cluster_at',end_timepoint,sep = '_'),'~.',sep = ''))
acc <- c()
tra <- c()
for (j in 1:ncol(train_index)){
# Split train and test sets
trainset = logreg[train_index[,j],]
testset = logreg[-train_index[,j],]
if (all(apply(X = logreg, MARGIN = 2, FUN = function(x){length(unique(x))})== apply(X = trainset, MARGIN = 2, FUN = function(x){length(unique(x))}))){
# Create a model
prediction_model <- multinom(formula = fo , data = trainset ,censored = T, model = T)
# Predict for the trainset
training_set_accuracies <- prediction_model %>% predict(trainset)
# Predict for the testset
test_set_predictions <- prediction_model %>% predict(testset)
# Calculate accuracies
acc[j] = (sum(test_set_predictions == testset[,1])/ nrow(testset)) *100
tra[j] = (sum(training_set_accuracies == trainset[,1])/nrow(trainset))*100
}
}
# Remove NAs
acc = na.omit(acc)
tra = na.omit(tra)
Test_set_stratified_accuracy <- mean(acc)
Train_set_stratified_accuracy = mean(tra)
trainsd <- sd(tra)
testsd <- sd(acc)
return (c(Test_set_stratified_accuracy,Train_set_stratified_accuracy, trainsd,testsd))
}
###################### Calculate optimal split percentage ######################
# Calculate the optimal split percentage between .65 and .90 for predicting the final timepoint on the
# exact previous one to be used in all splits for all timepoints. The criterion is the best accuracy
# as derived by the previous function with argument the different percentages.
optimal_splitting_percentage <- function (dataset_full){
all_calculated_accuracies <- c()
best_splitting_percentage <- c()
for (percentage_to_calculate in 65:90){
percentage_to_calculate = percentage_to_calculate/100
telika <- multilogreg_stratified(end_timepoint = end_timepoint,dataset_full = dataset_full, optimal_splitting_percentage = percentage_to_calculate, timepoint = rev(colnames(dataset_full))[2], splitting_times = splitting_times)
Test_set_stratified_accuracy = telika[1]
Train_set_stratified_accuracy = telika[2]
trainsd = telika[3]
testsd = telika[4]
all_calculated_accuracies= c(all_calculated_accuracies,Test_set_stratified_accuracy)
best_splitting_percentage = c(best_splitting_percentage,percentage_to_calculate)
}
return (best_splitting_percentage[which.max(all_calculated_accuracies)])
}
# Assign the best percentage on a variable to use on the final calculations
optimal_splitting_percentage <- optimal_splitting_percentage(dataset_full = dataset_full)
###################### Initializing variables All #############################
Test_set_LOO_accuracy <- c()
Train_set_LOO_accuracy <-c()
Test_set_stratified_accuracy <- c()
Train_set_stratified_accuracy <- c()
trainsd <- c()
testsd <- c()
###################### Calculate Accuracies on timepoints All #################
for (timepoint in timepoints_to_perform){
LOOTeliko <- LOO_multilogreg(dataset_full = dataset_full, timepoint = timepoint,end_timepoint = end_timepoint, splitting_times = splitting_times)
Train_set_LOO_accuracy = c(Train_set_LOO_accuracy,LOOTeliko[1])
Test_set_LOO_accuracy = c(Test_set_LOO_accuracy,LOOTeliko[2])
MultiLogReg_results <- multilogreg_stratified(dataset_full, optimal_splitting_percentage, timepoint, times = 100,end_timepoint = end_timepoint,splitting_times = splitting_times)
Test_set_stratified_accuracy <- c(Test_set_stratified_accuracy,MultiLogReg_results[1])
Train_set_stratified_accuracy <- c(Train_set_stratified_accuracy, MultiLogReg_results[2])
trainsd <- c(trainsd, MultiLogReg_results[3])
testsd <- c(testsd, MultiLogReg_results[4])
}
###################### Save accuracies on the lists ######################################
Train_sets_LOO = rbind (Train_sets_LOO,  c('All',rep(0,(ncol(dataset_full)-length(Train_set_LOO_accuracy)-1)),Train_set_LOO_accuracy))
Test_sets_LOO  = rbind (Test_sets_LOO,   c('All',rep(0,(ncol(dataset_full)-length(Test_set_LOO_accuracy)-1)),Test_set_LOO_accuracy))
Test_sets_stratified_split  = rbind (Test_sets_stratified_split,   c('All',rep(0,(ncol(dataset_full)-length(Test_set_stratified_accuracy)-1)),Test_set_stratified_accuracy))
Train_sets_stratified_split = rbind (Train_sets_stratified_split,  c('All',rep(0,(ncol(dataset_full)-length(Train_set_stratified_accuracy)-1)),Train_set_stratified_accuracy))
Train_stratified_overtime_accuracy <- c(Train_set_stratified_accuracy,Train_stratified_overtime_accuracy)
Test_stratified_overtime_accuracy  <- c(Test_set_stratified_accuracy ,Test_stratified_overtime_accuracy)
Train_LOO_overtime_accuracy <- c(Train_set_LOO_accuracy,Train_LOO_overtime_accuracy)
Test_LOO_overtime_accuracy  <- c(Test_set_LOO_accuracy, Test_LOO_overtime_accuracy)
}
###################### Calculate all possible combinations of metadata calculated ##########################
Npredictions = 0
for (r in 1:length(effectors)){
Npredictions= Npredictions +(nrow(combinations(n = length(effectors),r = r,v = effectors,set = T,repeats.allowed = F)))
}
Npredictions = Npredictions +1
###################### Write files of All Calculated Accuracies ############################################
rownames(Train_sets_stratified_split) = Train_sets_stratified_split[,1]
rownames(Train_sets_LOO)= Train_sets_LOO[,1]
rownames(Test_sets_LOO) = Test_sets_LOO[,1]
rownames(Test_sets_stratified_split)= Test_sets_stratified_split[,1]
Train_sets_stratified_split = Train_sets_stratified_split[,2:ncol(Train_sets_stratified_split)]
Test_sets_stratified_split = Test_sets_stratified_split[,2:ncol(Test_sets_stratified_split)]
Train_sets_LOO =Train_sets_LOO[,2:ncol(Train_sets_LOO)]
Test_sets_LOO = Test_sets_LOO[,2:ncol(Test_sets_LOO)]
colnames(Train_sets_LOO) = c(paste('From timepoint ',rev(colnames(dataset_full)[1:ncol(dataset_full)-1]),sep = ''))
colnames(Test_sets_LOO)  = c(paste('From timepoint ',rev(colnames(dataset_full)[1:ncol(dataset_full)-1]),sep = ''))
colnames(Train_sets_stratified_split) = c(paste('From timepoint ',rev(colnames(dataset_full)[1:ncol(dataset_full)-1]),sep = ''))
colnames(Test_sets_stratified_split)  = c(paste('From timepoint ',rev(colnames(dataset_full)[1:ncol(dataset_full)-1]),sep = ''))
write.table(x = Train_sets_LOO, file = paste(output_dir,'All Accuracies of Training Sets LOO.tab', sep = '/') , sep = "\t",col.names =NA, row.names = TRUE,quote = FALSE)
write.table(x = Test_sets_LOO,  file = paste(output_dir,'All Accuracies of Test Sets LOO.tab',     sep = '/') , sep = "\t",col.names =NA, row.names = TRUE,quote = FALSE)
write.table(x = Train_sets_stratified_split, file = paste(output_dir,'All Accuracies of Training Sets Splitted.tab', sep = '/') , sep = "\t",col.names =NA, row.names = TRUE,quote = FALSE)
write.table(x = Test_sets_stratified_split,  file = paste(output_dir,'All Accuracies of Test Sets Splitted.tab', sep = '/')  , sep = "\t",col.names =NA, row.names = TRUE,quote = FALSE)
###################### Barplots of Accuracies ############################################
# Create a directory wherre the acuuracy related files will be placed
dir.create(paste(output_dir,"Accuracies",sep = '/'),showWarnings = F)
# Counting indices
row <- 1 ; column <- 0
# Calculate the maximum accuracy for every timepoint
for (x in 1:ncol(Train_sets_LOO)){
# Vector with the maximum accuracies and the metadata
max_Train_sets_LOO <- c()
meta_Train_sets_LOO <- c()
max_Test_sets_LOO <- c()
meta_Test_sets_LOO <- c()
max_Train_sets_stratified_split <- c()
meta_Train_sets_stratified_split <- c()
max_Test_sets_stratified_split <- c()
meta_Test_sets_stratified_split <- c()
for (y in 1:ncol(Train_sets_LOO)){
if ((column+y) <= ncol(Train_sets_LOO)){
max_Train_sets_LOO <- c( max_Train_sets_LOO, max(as.numeric(Train_sets_LOO[row:(row+Npredictions-1),column+y])))
meta_Train_sets_LOO <- c(meta_Train_sets_LOO, names(which(Train_sets_LOO[row:(row+Npredictions-1),column+y]== as.character(max(as.numeric(Train_sets_LOO[row:(row+Npredictions-1),column+y]))))[1]))
max_Test_sets_LOO <- c( max_Test_sets_LOO,max(as.numeric(Test_sets_LOO[row:(row+Npredictions-1),column+y])))
meta_Test_sets_LOO <- c(meta_Test_sets_LOO, names(which(Test_sets_LOO[row:(row+Npredictions-1),column+y]== as.character(max(as.numeric(Test_sets_LOO[row:(row+Npredictions-1),column+y]))))[1]))
max_Train_sets_stratified_split <- c( max_Train_sets_stratified_split, max(as.numeric(Train_sets_stratified_split[row:(row+Npredictions-1),column+y])))
meta_Train_sets_stratified_split<- c(meta_Train_sets_stratified_split, names(which(Train_sets_stratified_split[row:(row+Npredictions-1),column+y]== as.character(max(as.numeric(Train_sets_stratified_split[row:(row+Npredictions-1),column+y]))))[1]))
max_Test_sets_stratified_split <- c( max_Test_sets_stratified_split, max(as.numeric(Test_sets_stratified_split[row:(row+Npredictions-1),column+y])))
meta_Test_sets_stratified_split <- c(meta_Test_sets_stratified_split, names(which(Test_sets_stratified_split[row:(row+Npredictions-1),column+y]== as.character( max(as.numeric(Test_sets_stratified_split[row:(row+Npredictions-1),column+y]))))[1]))
}
}
# Save the accuracies in the heatmap matrix
heatmap_matrix_statified[(length(heatmap_matrix_statified)-column),c(1:length(max_Test_sets_stratified_split))] <- rev(max_Test_sets_stratified_split)
heatmap_matrix_LOO[(length(heatmap_matrix_LOO)-column),c(1:length(max_Test_sets_LOO))] <- rev(max_Test_sets_LOO)
# Formation of the metadata matrix
temp_df_meta <- data.frame(rbind(rev(meta_Test_sets_LOO),rev(meta_Test_sets_stratified_split), rev(meta_Train_sets_LOO),rev(meta_Train_sets_stratified_split)))
temp_df_meta <- data.frame(c("Test_sets_LOO","Test_sets_stratified_split","Train_sets_LOO","Train_sets_stratified_split"),temp_df_meta)
colnames(temp_df_meta) <- c("rows",colnames(dataset_full_on_clusters)[1:(ncol(Train_sets_LOO)-column)])
# Unpivot temp_df_meta from wide to long format using the row names as the identifier
temp_df_meta <-  data.frame(melt(temp_df_meta, cols = 2:ncol(temp_df_meta),id.vars ="rows"))
colnames(temp_df_meta) <- c("Clusters","Timepoints","Percentages")
# Convert Timepoints and Cluster columns into factors
temp_df_meta[,"Clusters"] <- factor(temp_df_meta[,"Clusters"],levels = unique(temp_df_meta[,"Clusters"]))
temp_df_meta[,"Timepoints"] <- factor( temp_df_meta[,"Timepoints"], levels=colnames(dataset_full_on_clusters)[1:(ncol(Train_sets_LOO)-column)])
# Formation of the accuracies matrix
temp_df <- data.frame(rbind(rev(max_Test_sets_LOO),rev(max_Test_sets_stratified_split), rev(max_Train_sets_LOO),rev(max_Train_sets_stratified_split)))
temp_df <- data.frame(c("Test_sets_LOO","Test_sets_stratified_split","Train_sets_LOO","Train_sets_stratified_split"),temp_df)
colnames(temp_df) <- c("rows",colnames(dataset_full_on_clusters)[1:(ncol(Train_sets_LOO)-column)])
# Unpivot temp_df from wide to long format using the row names as the identifier
temp_df <-  data.frame(melt(temp_df, cols = 2:ncol(temp_df),id.vars ="rows"))
colnames(temp_df) <- c("Clusters","Timepoints","Percentages")
# Convert Timepoints and Cluster columns into factors
temp_df[,"Clusters"] <- factor(temp_df[,"Clusters"],levels = unique(temp_df[,"Clusters"]))
temp_df[,"Timepoints"] <- factor( temp_df[,"Timepoints"], levels=colnames(dataset_full_on_clusters)[1:(ncol(Train_sets_LOO)-column)])
temp_df <- data.frame(temp_df, meta=as.factor(temp_df_meta[,3]))
# Create a vector with the colours for the barplot
color <-colours_ploting[1:nlevels(as.factor(temp_df[,"Clusters"]))]
# Barplot of the Accuracies
barplot <-  ggplot(data=temp_df, aes(x=Timepoints, y=Percentages)) +
scale_y_continuous(limits=c(0,100),breaks = c(0,20,40,60,80,100))+
geom_bar(aes(fill= Clusters),stat="identity", position="dodge",alpha=0.7)+
geom_text(aes(x=Timepoints, y=Percentages,label=meta, group = Clusters),position = position_dodge(width = .9),angle=90,hjust=2.5)+
ylab("Acurracy")+
ggtitle(paste("Accuracy achieved on Timepoint:",rev(colnames(dataset_full_on_clusters))[x]))+
scale_fill_manual(breaks=c(levels(factor(temp_df[,"Clusters"],levels = unique(temp_df[,"Clusters"])))), values=color)+
guides(fill=guide_legend(title=""))+
geom_hline(yintercept = (1/nlevels(as.factor(dataset_full_on_clusters[,rev(colnames(dataset_full_on_clusters))[x]])))*100, linetype = "dashed")+
theme_classic()+
theme(legend.title.align = 0.5,plot.title = element_text(hjust = 0.5))+
scale_fill_manual(values = c('paleturquoise4','paleturquoise3', 'darkolivegreen2', 'darkolivegreen3'),guide="none")
# Calculate the initial line for the next iteration
row <- row+Npredictions
# Calculate the initial column for the next iteration
column=column+1
# Print the barplots
ggsave(paste(paste(output_dir,"Accuracies",sep = '/'),paste(paste('Accuracies of Models on Timepoint', rev(colnames(dataset_full_on_clusters))[column],sep = ' '),'pdf', sep='.'),sep = '/'),barplot)
jpeg(filename = paste(paste(output_dir,"Accuracies",sep = '/'),paste(paste('Accuracies of Models on Timepoint', rev(colnames(dataset_full_on_clusters))[column],sep = ' '),'jpeg', sep='.'),sep = '/'))
print(barplot)
dev.off()
}
# Function for the Heatmaps
heatmap <- function (heatmap_matrix,category) {
# Name the rows and columns of the heatmap matrix
rownames(heatmap_matrix) <- colnames(dataset_full_on_clusters)
colnames(heatmap_matrix) <- colnames(dataset_full_on_clusters)
# Unpivot heatmap_matrix from wide to long format using the rownames as the identifier
heatmap_matrix <- t(heatmap_matrix)
heatmap_matrix <- data.frame(rownames(heatmap_matrix),heatmap_matrix)
colnames(heatmap_matrix)[2:ncol(heatmap_matrix)] <- colnames(dataset_full_on_clusters)
melted_heatmap <- melt(heatmap_matrix, na.rm = TRUE)
colnames(melted_heatmap) <- c("X","Y","Value")
# Convert X and Y columns into factors
melted_heatmap[,"X"] <- factor( melted_heatmap[,"X"] , levels=colnames(dataset_full_on_clusters))
melted_heatmap[,"Y"] <- factor( melted_heatmap[,"Y"] , levels=colnames(dataset_full_on_clusters))
# Heatmap
heatmap_plot <-  ggplot(data = melted_heatmap, aes(X, Y, fill = Value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 50, limit = c(0,100), space = "Lab", name="Accuracy") +
theme_minimal()+
ylab("Timepoints")+
xlab("Timepoints")+
coord_fixed()+
geom_text(aes(X, Y, label = round(Value,2)), color = "black", size = 4) +
theme(plot.title = element_text(hjust = 0.5,size=20, face = "bold"),
legend.box.just = "left",
axis.text.x = element_text(size = 12, face = "bold"),
axis.text.y = element_text(size = 12, face = "bold"),
panel.grid.major = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
legend.justification = c(0, 1),
legend.position = c(0.7, 0.3),
legend.direction = "horizontal")+
guides(fill = guide_colorbar(barwidth = 7, barheight = 1, title.position = "top", title.hjust = 0.5))+
ggtitle(paste0("Heatmap of Accuracies (",category,")"))
# Print the heatmap
ggsave(paste(paste(output_dir,"Accuracies",sep = '/'),paste0('Heatmap(',category,').pdf'),sep = '/'),heatmap_plot)
jpeg(filename = paste(paste(output_dir,"Accuracies",sep = '/'),paste0('Heatmap(',category,').jpeg'),sep = '/'))
print(heatmap_plot)
dev.off()
}
# Print the LOO heatmap
heatmap(heatmap_matrix_LOO,"LOO")
# Print the stratified Split heatmap
heatmap(heatmap_matrix_statified,"Stratified Split")
###################### Calculate random estimators performance ##########################################
random_estimator = 100/rev(apply (X = dataset_full,MARGIN = 2,FUN = function(x){max(x,na.rm = T)}))
###################### Write files of Best Accuracies Test_sets_LOO ###########################################
TotimepointIndeces = c(0:ncol(Test_sets_LOO))*Npredictions
maxaccuracies <- c()
metadata <- c()
for (i in 1:(length(TotimepointIndeces)-1)){
maxaccuracies[i] <-  max(as.numeric(Test_sets_LOO[(1+TotimepointIndeces[i]):TotimepointIndeces[i+1],i]))
metadata[i] <-  names(which(Test_sets_LOO[(1+TotimepointIndeces[i]):TotimepointIndeces[i+1],i]== as.character(max(as.numeric(Test_sets_LOO[(1+TotimepointIndeces[i]):TotimepointIndeces[i+1],i]))))[1])
}
write.table(x = rbind(paste(paste('Maximum Accuracy for Timepoint', rev(colnames(dataset_full)[2:ncol(dataset_full)])), c(rev(colnames(dataset_full))[2:ncol(dataset_full)]), sep = ' from Timepoint '),maxaccuracies,metadata,random_estimator[1:length(random_estimator)-1]),
file = paste(output_dir,'Maximum_Accuracies_of_Test_sets_LOO.tab',sep = '/'), sep = "\t",col.names =NA, row.names = TRUE,quote = FALSE)
###################### Write files of Best Accuracies TestSplits ########################################
maxaccuracies <- c()
metadata <- c()
for (i in 1:(length(TotimepointIndeces)-1)){
maxaccuracies[i] <-  max(as.numeric(Test_sets_stratified_split[(1+TotimepointIndeces[i]):TotimepointIndeces[i+1],i]))
metadata[i] <-  names(which(Test_sets_stratified_split[(1+TotimepointIndeces[i]):TotimepointIndeces[i+1],i]== as.character(max(as.numeric(Test_sets_stratified_split[(1+TotimepointIndeces[i]):TotimepointIndeces[i+1],i]))))[1])
}
write.table(x = rbind(paste(paste('Maximum Accuracy for Timepoint', rev(colnames(dataset_full)[2:ncol(dataset_full)])), c(rev(colnames(dataset_full))[2:ncol(dataset_full)]), sep = ' from Timepoint '),maxaccuracies,metadata,random_estimator[1:length(random_estimator)-1])
,file = paste(output_dir,'Maximum_Accuracies_of_Stratified_Tests.tab',sep = '/'), sep = "\t",col.names =NA, row.names = TRUE,quote = FALSE)
###################### Write files of Best Accuracies Train_sets_LOO ########################################
maxaccuracies <- c()
metadata <- c()
for (i in 1:(length(TotimepointIndeces)-1)){
maxaccuracies[i] <-  max(as.numeric(Train_sets_LOO[(1+TotimepointIndeces[i]):TotimepointIndeces[i+1],i]))
metadata[i] <-  names(which(Train_sets_LOO[(1+TotimepointIndeces[i]):TotimepointIndeces[i+1],i]== as.character(max(as.numeric(Train_sets_LOO[(1+TotimepointIndeces[i]):TotimepointIndeces[i+1],i]))))[1])
}
write.table(x = rbind(paste(paste('Maximum Accuracy for Timepoint', rev(colnames(dataset_full)[2:ncol(dataset_full)])), c(rev(colnames(dataset_full))[2:ncol(dataset_full)]), sep = ' from Timepoint '),maxaccuracies,metadata,random_estimator[1:length(random_estimator)-1])
,file = paste(output_dir,'Maximum_Accuracies_of_Train_sets_LOO.tab',sep = '/'), sep = "\t",col.names =NA, row.names = TRUE,quote = FALSE)
###################### Write files of Best Accuracies TrainSplits ########################################
maxaccuracies <- c()
metadata <- c()
for (i in 1:(length(TotimepointIndeces)-1)){
maxaccuracies[i] <-  max(as.numeric(Train_sets_stratified_split[(1+TotimepointIndeces[i]):TotimepointIndeces[i+1],i]))
metadata[i] <-  names(which(Train_sets_stratified_split[(1+TotimepointIndeces[i]):TotimepointIndeces[i+1],i]== as.character(max(as.numeric(Train_sets_stratified_split[(1+TotimepointIndeces[i]):TotimepointIndeces[i+1],i]))))[1])
}
write.table(x = rbind(paste(paste('Maximum Accuracy for Timepoint', rev(colnames(dataset_full)[2:ncol(dataset_full)])), c(rev(colnames(dataset_full))[2:ncol(dataset_full)]), sep = ' from Timepoint '),maxaccuracies,metadata,random_estimator[1:length(random_estimator)-1]),
file = paste(output_dir,'Maximum_Accuracies_of_TrainSplits.tab',sep = '/'), sep = "\t",col.names =NA, row.names = TRUE,quote = FALSE)
###################### Perform Chi-square analysis to check metadata influence on T0 #####################
# Create a matrix to check for the effect of the metadata on the first timepoint (T0)
chimatrix = matrix (NA, ncol = length(effectors)+1, nrow = nrow(dataset_full))
# Assign the rownames to the matrix
rownames(chimatrix) = rownames(dataset_full)
# Assign the values on the matrix
chimatrix[,1] = dataset_full[,1]
for (chirow in rownames(dataset_full)){
subTab = as.matrix(meta_file[meta_file[,'Sample']==chirow & meta_file[,'Timepoint']==1,3:ncol(meta_file)])
if (length(subTab)){
chimatrix[chirow,2:ncol(chimatrix)] = subTab
}
}
chimatrix = chimatrix[complete.cases(chimatrix),]
Nuniq = length(unique(chimatrix[,1]))
Significant_metadata = c()
for (metadatum in 2:ncol(chimatrix)){
chi_square_value = 0
dof = 0
for (secondstate in unique(chimatrix[,metadatum])){
expected = sum(chimatrix[,metadatum]==secondstate) * (1/length(unique(chimatrix[,1])))
for (firstcluster in unique(chimatrix[,1])){
dof = dof + 1
observed = sum(chimatrix[chimatrix[,metadatum]== secondstate,1]==firstcluster)
chi_square_value = chi_square_value + ((observed- expected)**2)/expected
}
}
Null_hypothesis = chi_square_value <= qchisq(.95, df = (dof-1),lower.tail = T)
Significant_metadata[metadatum] = Null_hypothesis
}
Significant_metadata = Significant_metadata[2:length(Significant_metadata)]
if (any(Significant_metadata)){
Significant_metadata = colnames(meta_file)[3:ncol(meta_file)][Significant_metadata]
}
print (paste('The transitions among timepoints ',ifelse(test = Markovian_property, yes = 'are Markovian', no = 'are NOT Markovian'),sep = ' '))
print (paste('For the clustering fate on the first timepoint', paste(ifelse(test = Significant_metadata, yes = Significant_metadata, no = 'No'), 'metadata are significant.', sep = ' '), sep = ' '))
print (' Analysis Completed ')
print ('_____________________________________________')
print ('Results are saved in the preselected folders ')
print ('_____________________________________________')
} else {
print (paste('Cronos has already run with the exact same parameters. The output files are stored in',sub(pattern = './',replacement = '',x = directory),sep = ' '))
}
